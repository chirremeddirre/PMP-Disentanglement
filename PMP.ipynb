{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "830f3976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85bd189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f97f37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Transforms images to a PyTorch Tensor\\ntensor_transform = transforms.ToTensor()\\n  \\n# Download the MNIST Dataset\\nMNIST_dataset = datasets.MNIST(root = \"./data\",\\n                         train = True,\\n                         download = True,\\n                         transform = tensor_transform)\\n  \\n# DataLoader is used to load the dataset \\n# for training\\nMNIST_loader = torch.utils.data.DataLoader(dataset = MNIST_dataset,\\n                                     batch_size = 32,\\n                                     shuffle = True)\\n                                     '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Transforms images to a PyTorch Tensor\n",
    "tensor_transform = transforms.ToTensor()\n",
    "  \n",
    "# Download the MNIST Dataset\n",
    "MNIST_dataset = datasets.MNIST(root = \"./data\",\n",
    "                         train = True,\n",
    "                         download = True,\n",
    "                         transform = tensor_transform)\n",
    "  \n",
    "# DataLoader is used to load the dataset \n",
    "# for training\n",
    "MNIST_loader = torch.utils.data.DataLoader(dataset = MNIST_dataset,\n",
    "                                     batch_size = 32,\n",
    "                                     shuffle = True)\n",
    "                                     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "499a6bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(737280, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "dataset = np.load(\"../dsprites-dataset/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz\")\n",
    "print(dataset['imgs'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a47b72ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bade54cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dSpritesDataset(Dataset):\n",
    "    def __init__(self, ds):\n",
    "        self.data = ds['imgs']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = np.expand_dims(self.data[idx], axis=0)\n",
    "        img = torch.tensor(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "707e191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarB1Dataset(Dataset):\n",
    "    def __init__(self, dic):\n",
    "        self.data = dic[b'data']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.tensor(self.data[idx])\n",
    "        data = torch.reshape(data, (3,32,32))/255\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7468f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_batch(batch):\n",
    "    split_size = batch.size(dim=0)//2\n",
    "    x1, x2 = torch.split(batch, split_size)\n",
    "    return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2273e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = unpickle(\"../cifar-10-batches-py/data_batch_1\")\n",
    "training_data = dSpritesDataset(dataset) #CifarB1Dataset(dic)\n",
    "batch_size = 50\n",
    "cifar_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_dataloader = cifar_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a26e81d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, size = 32, chan = 3):\n",
    "        super().__init__()\n",
    "        self.conv =  nn.Sequential(nn.Conv2d(chan,8,3,stride=1,padding=1),\n",
    "                                     torch.nn.ReLU(),\n",
    "                                     nn.Conv2d(8,16,4,stride=2,padding=1),\n",
    "                                     torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.encoder = nn.Sequential(nn.Linear((size//2)*(size//2)*16, 256),\n",
    "                                     torch.nn.ReLU(),\n",
    "                                     nn.Linear(256,128),\n",
    "                                     torch.nn.ReLU(),\n",
    "                                     nn.Linear(128,64),\n",
    "                                     torch.nn.ReLU(),\n",
    "                                     nn.Linear(64,36),\n",
    "                                     torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.upconv = nn.Sequential(nn.ConvTranspose2d(1,3,3,stride = 2, padding = 1),\n",
    "                                    torch.nn.ReLU(),\n",
    "                                    nn.ConvTranspose2d(3,8,3,stride = 1, padding = 1),\n",
    "                                    torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(nn.Linear(8*11*11,1024),\n",
    "                                     torch.nn.ReLU(),\n",
    "                                     nn.Linear(1024,1536),\n",
    "                                     torch.nn.ReLU(),\n",
    "                                     #nn.Linear(64,128),\n",
    "                                     #torch.nn.ReLU(),\n",
    "                                     #nn.Linear(128,256),\n",
    "                                     #torch.nn.ReLU(),\n",
    "                                     nn.Linear(1536,size*size*chan),\n",
    "                                     torch.nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = 0\n",
    "        if len(x.size()) > 3:\n",
    "            batch_size = x.size()[0]\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.encoder(x)\n",
    "        x = torch.reshape(x, (batch_size,1,6,6))\n",
    "        x = self.upconv(x)\n",
    "        #rint(x.size())\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.decoder(x)\n",
    "        #x = torch.reshape(x, (batch_size, 3, 32, 32))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cde46ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMP_Encoder(nn.Module):\n",
    "    def  __init__(self,d, chan):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(chan,32,4,stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32,32,4,stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32,64,4,stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64,64,4,stride=2, padding=1)\n",
    "        self.fc = nn.Linear(64*4*4,256)\n",
    "        self.z = nn.Linear(256, d)\n",
    "    \n",
    "    def forward(self, x1 , x2):\n",
    "        x1 = F.relu(self.conv1(x1))\n",
    "        x1 = F.relu(self.conv2(x1))\n",
    "        x1 = F.relu(self.conv3(x1))\n",
    "        z1 = F.relu(self.conv4(x1))\n",
    "        #print(z1.size())\n",
    "        x2 = F.relu(self.conv1(x2))\n",
    "        x2 = F.relu(self.conv2(x2))\n",
    "        x2 = F.relu(self.conv3(x2))\n",
    "        z2 = F.relu(self.conv4(x2))\n",
    "        z1 = torch.flatten(z1,1)\n",
    "        z1 = F.relu(self.fc(z1))\n",
    "        s1 = self.z(z1)\n",
    "        z2 = torch.flatten(z2,1)\n",
    "        z2 = F.relu(self.fc(z2))\n",
    "        s2 = self.z(z2)\n",
    "        return s1, s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69dcdccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMP_Decoder(nn.Module):\n",
    "    def  __init__(self, d, chan):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d,256)\n",
    "        self.fc2 = nn.Linear(256,256)\n",
    "        self.fc3 = nn.Linear(256, 64*4*4)\n",
    "        # Reshape into 64x4x4\n",
    "        self.convt1 = nn.ConvTranspose2d(64, 64, 4,stride=2,padding=1)\n",
    "        self.convt2 = nn.ConvTranspose2d(64, 32, 4,stride=2,padding=1)\n",
    "        self.convt3 = nn.ConvTranspose2d(32, 32, 4,stride=2,padding=1)\n",
    "        self.convt4 = nn.ConvTranspose2d(32, chan, 4,stride=2,padding=1)\n",
    "    \n",
    "    def forward(self, z1, z2, batch_size):\n",
    "        z1 = F.relu(self.fc1(z1))\n",
    "        z1 = F.relu(self.fc2(z1))\n",
    "        z1 = F.relu(self.fc3(z1))\n",
    "        z2 = F.relu(self.fc1(z2))\n",
    "        z2 = F.relu(self.fc2(z2))\n",
    "        z2 = F.relu(self.fc3(z2))\n",
    "        #print(z1.size())\n",
    "        #print(f\"batch_size = {batch_size}\")\n",
    "        z1 = torch.reshape(z1, (batch_size, 64,4,4))\n",
    "        z2 = torch.reshape(z2, (batch_size, 64,4,4))\n",
    "\n",
    "        z1 = F.relu(self.convt1(z1))\n",
    "        z1 = F.relu(self.convt2(z1))\n",
    "        z1 = F.relu(self.convt3(z1))\n",
    "        x1 = F.relu(self.convt4(z1))\n",
    "\n",
    "        z2 = F.relu(self.convt1(z2))\n",
    "        z2 = F.relu(self.convt2(z2))\n",
    "        z2 = F.relu(self.convt3(z2))\n",
    "        x2 = F.relu(self.convt4(z2))\n",
    "\n",
    "        return x1, x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9579f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMP(nn.Module):\n",
    "    def __init__(self, d=10, chan=3, batch_size=2):\n",
    "        super(PMP, self).__init__()\n",
    "        self.d = d\n",
    "        self.chan = chan\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder = PMP_Encoder(self.d, self.chan)\n",
    "        self.decoder = PMP_Decoder(self.d, self.chan)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        z1, z2 = self.encoder(x1, x2)\n",
    "        x1_, x2_ = self.decoder(z1, z2, self.batch_size)\n",
    "        return x1_, x2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "adfa6ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMP(\n",
      "  (encoder): PMP_Encoder(\n",
      "    (conv1): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv4): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (fc): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (z): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      "  (decoder): PMP_Decoder(\n",
      "    (fc1): Linear(in_features=10, out_features=256, bias=True)\n",
      "    (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (fc3): Linear(in_features=256, out_features=1024, bias=True)\n",
      "    (convt1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (convt2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (convt3): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (convt4): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "size = 64\n",
    "channels = 1\n",
    "net = PMP(chan=channels, batch_size=batch_size//2).to(device)\n",
    "print(net)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),\n",
    "                             lr = 0.0005,\n",
    "                             weight_decay = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "731a95d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.000503\n",
      "[1,   201] loss: 0.044862\n",
      "[1,   401] loss: 0.041945\n",
      "[1,   601] loss: 0.042453\n",
      "[1,   801] loss: 0.042236\n",
      "[1,  1001] loss: 0.042650\n",
      "[1,  1201] loss: 0.042568\n",
      "[1,  1401] loss: 0.042172\n",
      "[1,  1601] loss: 0.042474\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3497/118481892.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx1_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3497/1960524591.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3497/166700412.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z1, z2, batch_size)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvt1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvt3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvt4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    921\u001b[0m             input, output_size, self.stride, self.padding, self.kernel_size, self.dilation)  # type: ignore[arg-type]\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         return F.conv_transpose2d(\n\u001b[0m\u001b[1;32m    924\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             output_padding, self.groups, self.dilation)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(35):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        x1, x2 = split_batch(data.float())\n",
    "        x1, x2 = x1.to(device), x2.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        x1_hat, x2_hat = net(x1,x2)\n",
    "        loss = criterion(torch.cat((x1,x2),0), torch.cat((x1_hat, x2_hat), 0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 0:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.6f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf520942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "im = torch.reshape(x1_hat[3],(channels,size,size))\n",
    "im = im.to(\"cpu\").detach().numpy()\n",
    "im = np.moveaxis(im,0,2)\n",
    "im_l = torch.reshape(x1[3],(channels,size,size)).to(\"cpu\").detach().numpy()\n",
    "im_l = np.moveaxis(im_l,0,2)\n",
    "k = 1\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "for i in range(3):\n",
    "  im = torch.reshape(x1_hat[i],(channels,size,size))\n",
    "  im = im.to(\"cpu\").detach().numpy()\n",
    "  im = np.moveaxis(im,0,2)\n",
    "  im_l = torch.reshape(x1[i],(channels,size,size)).to(\"cpu\").detach().numpy()\n",
    "  im_l = np.moveaxis(im_l,0,2)\n",
    "  fig.add_subplot(3,2,k)\n",
    "  plt.imshow(im_l)\n",
    "  k += 1\n",
    "  fig.add_subplot(3,2,k)\n",
    "  k += 1\n",
    "  plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a58bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "im = torch.reshape(x1_hat[0],(3,32,32)) #torch.movedim(x1_hat,0,2)\n",
    "im = im.detach().numpy()\n",
    "#print(im.shape)\n",
    "#print(x1_hat.size())\n",
    "plt.imshow(im.T)\n",
    "im_l = torch.reshape(x1[0],(3,32,32)).detach().numpy()\n",
    "plt.imshow(im_l.T)\n",
    "#X = dic[b'data']\n",
    "#X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
    "#im1 =np.array(dic[b'data'][5]).reshape(3,32,32).T\n",
    "\n",
    "print(im)\n",
    "#plt.imshow(im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e8c1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
