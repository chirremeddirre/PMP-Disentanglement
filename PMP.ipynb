{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "830f3976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85bd189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f97f37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Transforms images to a PyTorch Tensor\\ntensor_transform = transforms.ToTensor()\\n  \\n# Download the MNIST Dataset\\nMNIST_dataset = datasets.MNIST(root = \"./data\",\\n                         train = True,\\n                         download = True,\\n                         transform = tensor_transform)\\n  \\n# DataLoader is used to load the dataset \\n# for training\\nMNIST_loader = torch.utils.data.DataLoader(dataset = MNIST_dataset,\\n                                     batch_size = 32,\\n                                     shuffle = True)\\n                                     '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Transforms images to a PyTorch Tensor\n",
    "tensor_transform = transforms.ToTensor()\n",
    "  \n",
    "# Download the MNIST Dataset\n",
    "MNIST_dataset = datasets.MNIST(root = \"./data\",\n",
    "                         train = True,\n",
    "                         download = True,\n",
    "                         transform = tensor_transform)\n",
    "  \n",
    "# DataLoader is used to load the dataset \n",
    "# for training\n",
    "MNIST_loader = torch.utils.data.DataLoader(dataset = MNIST_dataset,\n",
    "                                     batch_size = 32,\n",
    "                                     shuffle = True)\n",
    "                                     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b726f64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(737280, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "dataset = np.load(\"../dsprites-dataset/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz\")\n",
    "print(dataset['imgs'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a47b72ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67904905",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dSpritesDataset(Dataset):\n",
    "    def __init__(self, ds):\n",
    "        self.data = ds['imgs']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = np.expand_dims(self.data[idx], axis=0)\n",
    "        img = torch.tensor(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "707e191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarB1Dataset(Dataset):\n",
    "    def __init__(self, dic):\n",
    "        self.data = dic[b'data']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.tensor(self.data[idx])\n",
    "        data = torch.reshape(data, (3,32,32))/255\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7468f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_batch(batch):\n",
    "    split_size = batch.size(dim=0)//2\n",
    "    x1, x2 = torch.split(batch, split_size)\n",
    "    return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2273e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = unpickle(\"../cifar-10-batches-py/data_batch_1\")\n",
    "training_data = dSpritesDataset(dataset) #CifarB1Dataset(dic)\n",
    "batch_size = 50\n",
    "cifar_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_dataloader = cifar_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a26e81d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, size = 32, chan = 3):\n",
    "        super().__init__()\n",
    "        self.conv =  nn.Sequential(nn.Conv2d(chan,8,3,stride=1,padding=1),\n",
    "                                     torch.nn.ReLU(),\n",
    "                                     nn.Conv2d(8,16,4,stride=2,padding=1),\n",
    "                                     torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.encoder = nn.Sequential(nn.Linear((size//2)*(size//2)*16, 256),\n",
    "                                     torch.nn.ReLU(),\n",
    "                                     nn.Linear(256,128),\n",
    "                                     torch.nn.ReLU(),\n",
    "                                     nn.Linear(128,64),\n",
    "                                     torch.nn.ReLU(),\n",
    "                                     nn.Linear(64,36),\n",
    "                                     torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.upconv = nn.Sequential(nn.ConvTranspose2d(1,3,3,stride = 2, padding = 1),\n",
    "                                    torch.nn.ReLU(),\n",
    "                                    nn.ConvTranspose2d(3,8,3,stride = 1, padding = 1),\n",
    "                                    torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(nn.Linear(8*11*11,1024),\n",
    "                                     torch.nn.ReLU(),\n",
    "                                     nn.Linear(1024,1536),\n",
    "                                     torch.nn.ReLU(),\n",
    "                                     #nn.Linear(64,128),\n",
    "                                     #torch.nn.ReLU(),\n",
    "                                     #nn.Linear(128,256),\n",
    "                                     #torch.nn.ReLU(),\n",
    "                                     nn.Linear(1536,size*size*chan),\n",
    "                                     torch.nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = 0\n",
    "        if len(x.size()) > 3:\n",
    "            batch_size = x.size()[0]\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.encoder(x)\n",
    "        x = torch.reshape(x, (batch_size,1,6,6))\n",
    "        x = self.upconv(x)\n",
    "        #rint(x.size())\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.decoder(x)\n",
    "        #x = torch.reshape(x, (batch_size, 3, 32, 32))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cde46ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMP_Encoder(nn.Module):\n",
    "    def  __init__(self,d, chan):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(chan,32,4,stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32,32,4,stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32,64,4,stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64,64,4,stride=2, padding=1)\n",
    "        self.fc = nn.Linear(64*4*4,256)\n",
    "        self.z = nn.Linear(256, d)\n",
    "    \n",
    "    def forward(self, x1 , x2):\n",
    "        x1 = F.relu(self.conv1(x1))\n",
    "        x1 = F.relu(self.conv2(x1))\n",
    "        x1 = F.relu(self.conv3(x1))\n",
    "        z1 = F.relu(self.conv4(x1))\n",
    "        #print(z1.size())\n",
    "        x2 = F.relu(self.conv1(x2))\n",
    "        x2 = F.relu(self.conv2(x2))\n",
    "        x2 = F.relu(self.conv3(x2))\n",
    "        z2 = F.relu(self.conv4(x2))\n",
    "        z1 = torch.flatten(z1,1)\n",
    "        z1 = F.relu(self.fc(z1))\n",
    "        s1 = self.z(z1)\n",
    "        z2 = torch.flatten(z2,1)\n",
    "        z2 = F.relu(self.fc(z2))\n",
    "        s2 = self.z(z2)\n",
    "        return s1, s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69dcdccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMP_Decoder(nn.Module):\n",
    "    def  __init__(self, d, chan):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d,256)\n",
    "        self.fc2 = nn.Linear(256,256)\n",
    "        self.fc3 = nn.Linear(256, 64*4*4)\n",
    "        # Reshape into 64x4x4\n",
    "        self.convt1 = nn.ConvTranspose2d(64, 64, 4,stride=2,padding=1)\n",
    "        self.convt2 = nn.ConvTranspose2d(64, 32, 4,stride=2,padding=1)\n",
    "        self.convt3 = nn.ConvTranspose2d(32, 32, 4,stride=2,padding=1)\n",
    "        self.convt4 = nn.ConvTranspose2d(32, chan, 4,stride=2,padding=1)\n",
    "    \n",
    "    def forward(self, z1, z2, batch_size):\n",
    "        z1 = F.relu(self.fc1(z1))\n",
    "        z1 = F.relu(self.fc2(z1))\n",
    "        z1 = F.relu(self.fc3(z1))\n",
    "        z2 = F.relu(self.fc1(z2))\n",
    "        z2 = F.relu(self.fc2(z2))\n",
    "        z2 = F.relu(self.fc3(z2))\n",
    "        #print(z1.size())\n",
    "        #print(f\"batch_size = {batch_size}\")\n",
    "        z1 = torch.reshape(z1, (batch_size, 64,4,4))\n",
    "        z2 = torch.reshape(z2, (batch_size, 64,4,4))\n",
    "\n",
    "        z1 = F.relu(self.convt1(z1))\n",
    "        z1 = F.relu(self.convt2(z1))\n",
    "        z1 = F.relu(self.convt3(z1))\n",
    "        x1 = F.relu(self.convt4(z1))\n",
    "\n",
    "        z2 = F.relu(self.convt1(z2))\n",
    "        z2 = F.relu(self.convt2(z2))\n",
    "        z2 = F.relu(self.convt3(z2))\n",
    "        x2 = F.relu(self.convt4(z2))\n",
    "\n",
    "        return x1, x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9579f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMP(nn.Module):\n",
    "    def __init__(self, d=10, chan=3, batch_size=2):\n",
    "        super(PMP, self).__init__()\n",
    "        self.d = d\n",
    "        self.chan = chan\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder = PMP_Encoder(self.d, self.chan)\n",
    "        self.decoder = PMP_Decoder(self.d, self.chan)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        z1, z2 = self.encoder(x1, x2)\n",
    "        x1_, x2_ = self.decoder(z1, z2, self.batch_size)\n",
    "        return x1_, x2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "adfa6ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMP(\n",
      "  (encoder): PMP_Encoder(\n",
      "    (conv1): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv4): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (fc): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (z): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      "  (decoder): PMP_Decoder(\n",
      "    (fc1): Linear(in_features=10, out_features=256, bias=True)\n",
      "    (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (fc3): Linear(in_features=256, out_features=1024, bias=True)\n",
      "    (convt1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (convt2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (convt3): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (convt4): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "size = 64\n",
    "channels = 1\n",
    "net = PMP(chan=channels, batch_size=batch_size//2)\n",
    "print(net)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),\n",
    "                             lr = 0.0005,\n",
    "                             weight_decay = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "731a95d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.000503\n",
      "[1,   201] loss: 0.044862\n",
      "[1,   401] loss: 0.041945\n",
      "[1,   601] loss: 0.042453\n",
      "[1,   801] loss: 0.042236\n",
      "[1,  1001] loss: 0.042650\n",
      "[1,  1201] loss: 0.042568\n",
      "[1,  1401] loss: 0.042172\n",
      "[1,  1601] loss: 0.042474\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3497/118481892.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx1_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3497/1960524591.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3497/166700412.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z1, z2, batch_size)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvt1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvt3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvt4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    921\u001b[0m             input, output_size, self.stride, self.padding, self.kernel_size, self.dilation)  # type: ignore[arg-type]\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         return F.conv_transpose2d(\n\u001b[0m\u001b[1;32m    924\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             output_padding, self.groups, self.dilation)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(35):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        x1, x2 = split_batch(data.float())\n",
    "        #print(x1.type())\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        x1_hat, x2_hat = net(x1,x2)\n",
    "        loss = criterion(torch.cat((x1,x2),0), torch.cat((x1_hat, x2_hat), 0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 0:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.6f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf520942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "im = torch.reshape(x1_hat[0],(channels,size,size))\n",
    "im = im.detach().numpy()\n",
    "im = np.moveaxis(im,0,2)\n",
    "im_l = torch.reshape(x1[0],(channels,size,size)).detach().numpy()\n",
    "im_l = np.moveaxis(im_l,0,2)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.imshow(im_l)\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a58bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "im = torch.reshape(x1_hat[0],(3,32,32)) #torch.movedim(x1_hat,0,2)\n",
    "im = im.detach().numpy()\n",
    "#print(im.shape)\n",
    "#print(x1_hat.size())\n",
    "plt.imshow(im.T)\n",
    "im_l = torch.reshape(x1[0],(3,32,32)).detach().numpy()\n",
    "plt.imshow(im_l.T)\n",
    "#X = dic[b'data']\n",
    "#X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
    "#im1 =np.array(dic[b'data'][5]).reshape(3,32,32).T\n",
    "\n",
    "print(im)\n",
    "#plt.imshow(im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e8c1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
